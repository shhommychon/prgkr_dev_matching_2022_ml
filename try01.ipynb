{
	"nbformat": 4,
	"nbformat_minor": 0,
	"metadata": {
		"colab": {
			"name": "2022 Dev-Matching: 머신러닝 과제테스트",
			"provenance": [],
			"collapsed_sections": [
				"XsTmffBdU9oJ"
			]
		},
		"kernelspec": {
			"name": "python3",
			"display_name": "Python 3"
		},
		"language_info": {
			"name": "python"
		},
		"accelerator": "GPU"
	},
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 1,
			"id": "90a05689-5084-415f-a08e-bf1889f548ec",
			"metadata": {},
			"outputs": [],
			"source": [
				"from baseline import data_loader as load"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"id": "35801619-b138-4b06-bfc9-5efc5d92b8be",
			"metadata": {},
			"outputs": [],
			"source": [
				"batch_size = 256"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"id": "049ba4ae-3077-41b0-b9e4-2e4bdaa27a3a",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"device cuda:0\n"
					]
				}
			],
			"source": [
				"device = load.device\n",
				"print(\"device\", device)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"id": "f2e71be4-7dfb-4d19-9667-4adbb3324df9",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"dataset0 labels:  ['n00020827', 'n01503061', 'n01661818', 'n02075296', 'n02087122', 'n02103406', 'n02159955', 'n03051540', 'n03100490', 'n03122748', 'n03294048', 'n03563967', 'n03574816', 'n04170037', 'n04341686']\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"/opt/ml/temp/baseline/data_loader.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
						"  dataset0_train_dataset = TensorDataset(torch.tensor(dataset0_X_train).float(), torch.from_numpy(dataset0_y_train))\n",
						"/opt/ml/temp/baseline/data_loader.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
						"  dataset0_test_dataset = TensorDataset(torch.tensor(dataset0_X_test).float(), torch.from_numpy(dataset0_y_test))\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\tdataset0 train shape:  torch.Size([256, 368, 5])\n",
						"\tdataset0 test shape:  torch.Size([256, 368, 5])\n",
						"\n",
						"dataset1 labels:  ['class0', 'class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9']\n",
						"\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"/opt/ml/temp/baseline/data_loader.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
						"  dataset1_train_dataset = TensorDataset(torch.tensor(dataset1_X_train).float(), torch.from_numpy(dataset1_y_train))\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\tdataset1 train shape:  torch.Size([256, 252, 5])\n",
						"\tdataset1 test shape:  torch.Size([256, 252, 5])\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"/opt/ml/temp/baseline/data_loader.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
						"  dataset1_test_dataset = TensorDataset(torch.tensor(dataset1_X_test).float(), torch.from_numpy(dataset1_y_test))\n"
					]
				}
			],
			"source": [
				"d0_train_loader, d0_test_loader, d1_train_loader, d1_test_loader = load.create_dataloader(batch_size=batch_size, enclude_dataset1_y=True)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"id": "64ec394d-129c-4f2a-80e3-b0ba5872eda9",
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"(26, 7, 7, 2)"
						]
					},
					"execution_count": 5,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"len(d0_train_loader), len(d0_test_loader), len(d1_train_loader), len(d1_test_loader)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"id": "58bb763a-14e4-4725-b87a-f91f918cc036",
			"metadata": {},
			"outputs": [],
			"source": [
				"import torch\n",
				"import torch.nn as nn\n",
				"from torchsummary import summary\n",
				"\n",
				"from utils import trainer as train\n",
				"from baseline import evaluator as eval\n",
				"\n",
				"from model.single_signal_stft_crnn import CRNN, MINDBIG_DATSET0 as cfg0, MINDBIG_DATSET1 as cfg1"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"id": "7115c1d9-64e4-4f82-9ade-588c1e4e35d7",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"{'n_fft': 35, 'class_num': 15}\n",
						"\n",
						"CRNN(\n",
						"  (STFT): SingleSignalSTFT()\n",
						"  (Conv1): ConvBlock(\n",
						"    (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
						"    (relu): ReLU()\n",
						"    (conv): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
						"    (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
						"  )\n",
						"  (Conv2): ConvBlock(\n",
						"    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
						"    (relu): ReLU()\n",
						"    (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
						"    (max_pool): MaxPool2d(kernel_size=(3, 2), stride=(3, 2), padding=0, dilation=1, ceil_mode=False)\n",
						"  )\n",
						"  (Conv3): ConvBlock(\n",
						"    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
						"    (relu): ReLU()\n",
						"    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
						"    (max_pool): MaxPool2d(kernel_size=(3, 2), stride=(3, 2), padding=0, dilation=1, ceil_mode=False)\n",
						"  )\n",
						"  (BiGRU): RNNBlock(\n",
						"    (BiGRU): GRU(64, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
						"  )\n",
						"  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 512))\n",
						"  (fc): Linear(in_features=512, out_features=15, bias=True)\n",
						")\n"
					]
				}
			],
			"source": [
				"print(cfg0)\n",
				"print()\n",
				"\n",
				"model = CRNN(n_fft=cfg0[\"n_fft\"], class_num=cfg0[\"class_num\"]).to(device)\n",
				"print(model)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"id": "c9b7db8e-829c-435b-bf44-a8913db73459",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"----------------------------------------------------------------\n",
						"        Layer (type)               Output Shape         Param #\n",
						"================================================================\n",
						"  SingleSignalSTFT-1            [-1, 18, 46, 2]               0\n",
						"       BatchNorm2d-2            [-1, 2, 18, 46]               4\n",
						"              ReLU-3            [-1, 2, 18, 46]               0\n",
						"            Conv2d-4           [-1, 16, 18, 46]             304\n",
						"         MaxPool2d-5            [-1, 16, 9, 23]               0\n",
						"         ConvBlock-6            [-1, 16, 9, 23]               0\n",
						"       BatchNorm2d-7            [-1, 16, 9, 23]              32\n",
						"              ReLU-8            [-1, 16, 9, 23]               0\n",
						"            Conv2d-9            [-1, 32, 9, 23]           4,640\n",
						"        MaxPool2d-10            [-1, 32, 3, 11]               0\n",
						"        ConvBlock-11            [-1, 32, 3, 11]               0\n",
						"      BatchNorm2d-12            [-1, 32, 3, 11]              64\n",
						"             ReLU-13            [-1, 32, 3, 11]               0\n",
						"           Conv2d-14            [-1, 64, 3, 11]          18,496\n",
						"        MaxPool2d-15             [-1, 64, 1, 5]               0\n",
						"        ConvBlock-16             [-1, 64, 1, 5]               0\n",
						"              GRU-17  [[-1, 5, 512], [-1, 2, 256]]               0\n",
						"         RNNBlock-18               [-1, 5, 512]               0\n",
						"AdaptiveAvgPool2d-19               [-1, 1, 512]               0\n",
						"           Linear-20                   [-1, 15]           7,695\n",
						"================================================================\n",
						"Total params: 31,235\n",
						"Trainable params: 31,235\n",
						"Non-trainable params: 0\n",
						"----------------------------------------------------------------\n",
						"Input size (MB): 0.01\n",
						"Forward/backward pass size (MB): 9.63\n",
						"Params size (MB): 0.12\n",
						"Estimated Total Size (MB): 9.76\n",
						"----------------------------------------------------------------\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"/opt/conda/lib/python3.8/site-packages/torch/functional.py:572: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
						"  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
					]
				}
			],
			"source": [
				"summary(model, (365, 5))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 9,
			"id": "42024f3a-710a-40bc-ad8f-b793d7bce1e4",
			"metadata": {},
			"outputs": [],
			"source": [
				"lr = 0.0001\n",
				"epochs = 20\n",
				"\n",
				"loss_ce = nn.CrossEntropyLoss()\n",
				"optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
				"scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.8, patience=2)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"id": "664e80ba-8501-40fc-b174-199022eb8731",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"epoch #000 train phase - \n",
						"\tloss : 2.7312, accuracy : 0.0000, macro_f1 : 0.0000\n",
						"epoch #000 test phase - \n",
						"\tloss : 2.6663, accuracy : 0.1865, macro_f1 : 0.0781\n",
						"\n",
						"epoch #001 train phase - \n",
						"\tloss : 2.7016, accuracy : 0.1657, macro_f1 : 0.0870\n",
						"epoch #001 test phase - \n",
						"\tloss : 2.6391, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #002 train phase - \n",
						"\tloss : 2.6780, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #002 test phase - \n",
						"\tloss : 2.6303, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #003 train phase - \n",
						"\tloss : 2.6397, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #003 test phase - \n",
						"\tloss : 2.6296, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #004 train phase - \n",
						"\tloss : 2.6325, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #004 test phase - \n",
						"\tloss : 2.6294, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #005 train phase - \n",
						"\tloss : 2.6309, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #005 test phase - \n",
						"\tloss : 2.6293, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #006 train phase - \n",
						"\tloss : 2.6308, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #006 test phase - \n",
						"\tloss : 2.6291, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #007 train phase - \n",
						"\tloss : 2.6307, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #007 test phase - \n",
						"\tloss : 2.6289, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #008 train phase - \n",
						"\tloss : 2.6302, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #008 test phase - \n",
						"\tloss : 2.6287, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #009 train phase - \n",
						"\tloss : 2.6303, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #009 test phase - \n",
						"\tloss : 2.6284, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #010 train phase - \n",
						"\tloss : 2.6304, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #010 test phase - \n",
						"\tloss : 2.6282, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #011 train phase - \n",
						"\tloss : 2.6299, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #011 test phase - \n",
						"\tloss : 2.6278, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #012 train phase - \n",
						"\tloss : 2.6301, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #012 test phase - \n",
						"\tloss : 2.6275, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #013 train phase - \n",
						"\tloss : 2.6304, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #013 test phase - \n",
						"\tloss : 2.6273, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #014 train phase - \n",
						"\tloss : 2.6296, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #014 test phase - \n",
						"\tloss : 2.6269, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #015 train phase - \n",
						"\tloss : 2.6299, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #015 test phase - \n",
						"\tloss : 2.6265, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #016 train phase - \n",
						"\tloss : 2.6302, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #016 test phase - \n",
						"\tloss : 2.6262, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #017 train phase - \n",
						"\tloss : 2.6291, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #017 test phase - \n",
						"\tloss : 2.6256, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #018 train phase - \n",
						"\tloss : 2.6295, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #018 test phase - \n",
						"\tloss : 2.6251, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"epoch #019 train phase - \n",
						"\tloss : 2.6298, accuracy : 0.1865, macro_f1 : 0.1771\n",
						"epoch #019 test phase - \n",
						"\tloss : 2.6247, accuracy : 0.1865, macro_f1 : 0.0958\n",
						"\n",
						"finished training\n",
						"best score - loss : 2.6247, accuracy : 0.1865, macro_f1 : 0.0958\n"
					]
				}
			],
			"source": [
				"train.train_dataset0(\n",
				"    model, d0_train_loader, d0_test_loader, \n",
				"    loss_ce, optimizer, scheduler,\n",
				"    epochs=epochs,\n",
				"    save_model_dir=\".model\", device=device\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 11,
			"id": "968c75ab-c5aa-41b2-b2a4-4d4724e305b8",
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"<All keys matched successfully>"
						]
					},
					"execution_count": 11,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"model = CRNN(n_fft=cfg0[\"n_fft\"], class_num=cfg0[\"class_num\"]).to(device)\n",
				"model.load_state_dict(torch.load(\".model/best_model.pt\"))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"id": "8d4c237c-fa9b-4416-881f-f521b0b353ac",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"{'n_fft': 34, 'class_num': 10}\n",
						"\n",
						"CRNN(\n",
						"  (STFT): SingleSignalSTFT()\n",
						"  (Conv1): ConvBlock(\n",
						"    (bn): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
						"    (relu): ReLU()\n",
						"    (conv): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
						"    (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
						"  )\n",
						"  (Conv2): ConvBlock(\n",
						"    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
						"    (relu): ReLU()\n",
						"    (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
						"    (max_pool): MaxPool2d(kernel_size=(3, 2), stride=(3, 2), padding=0, dilation=1, ceil_mode=False)\n",
						"  )\n",
						"  (Conv3): ConvBlock(\n",
						"    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
						"    (relu): ReLU()\n",
						"    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
						"    (max_pool): MaxPool2d(kernel_size=(3, 2), stride=(3, 2), padding=0, dilation=1, ceil_mode=False)\n",
						"  )\n",
						"  (BiGRU): RNNBlock(\n",
						"    (BiGRU): GRU(64, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
						"  )\n",
						"  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 512))\n",
						"  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
						")\n"
					]
				}
			],
			"source": [
				"print(cfg1)\n",
				"print()\n",
				"\n",
				"for param in model.parameters():\n",
				"    param.requires_grad = False\n",
				"\n",
				"model.fc = nn.Linear(in_features=512, out_features=cfg1[\"class_num\"])\n",
				"print(model)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"id": "e2f86f82-a2ae-43d9-af8e-ffd15a60d989",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"----------------------------------------------------------------\n",
						"        Layer (type)               Output Shape         Param #\n",
						"================================================================\n",
						"  SingleSignalSTFT-1            [-1, 18, 32, 2]               0\n",
						"       BatchNorm2d-2            [-1, 2, 18, 32]               4\n",
						"              ReLU-3            [-1, 2, 18, 32]               0\n",
						"            Conv2d-4           [-1, 16, 18, 32]             304\n",
						"         MaxPool2d-5            [-1, 16, 9, 16]               0\n",
						"         ConvBlock-6            [-1, 16, 9, 16]               0\n",
						"       BatchNorm2d-7            [-1, 16, 9, 16]              32\n",
						"              ReLU-8            [-1, 16, 9, 16]               0\n",
						"            Conv2d-9            [-1, 32, 9, 16]           4,640\n",
						"        MaxPool2d-10             [-1, 32, 3, 8]               0\n",
						"        ConvBlock-11             [-1, 32, 3, 8]               0\n",
						"      BatchNorm2d-12             [-1, 32, 3, 8]              64\n",
						"             ReLU-13             [-1, 32, 3, 8]               0\n",
						"           Conv2d-14             [-1, 64, 3, 8]          18,496\n",
						"        MaxPool2d-15             [-1, 64, 1, 4]               0\n",
						"        ConvBlock-16             [-1, 64, 1, 4]               0\n",
						"              GRU-17  [[-1, 4, 512], [-1, 2, 256]]               0\n",
						"         RNNBlock-18               [-1, 4, 512]               0\n",
						"AdaptiveAvgPool2d-19               [-1, 1, 512]               0\n",
						"           Linear-20                   [-1, 10]           5,130\n",
						"================================================================\n",
						"Total params: 28,670\n",
						"Trainable params: 5,130\n",
						"Non-trainable params: 23,540\n",
						"----------------------------------------------------------------\n",
						"Input size (MB): 0.00\n",
						"Forward/backward pass size (MB): 7.74\n",
						"Params size (MB): 0.11\n",
						"Estimated Total Size (MB): 7.85\n",
						"----------------------------------------------------------------\n"
					]
				}
			],
			"source": [
				"model.to(device)\n",
				"summary(model, (252, 5))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 14,
			"id": "64b7df5e-d1ec-4a76-b95e-9adbb3e86ee3",
			"metadata": {},
			"outputs": [],
			"source": [
				"lr = 0.0001\n",
				"epochs = 50\n",
				"\n",
				"loss_ce = nn.CrossEntropyLoss()\n",
				"optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
				"scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.8, patience=2)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 15,
			"id": "32fd42cf-1b0e-45c4-9935-09cf5cd01461",
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"epoch #000 train phase - \n",
						"\tloss : 2.3058, accuracy : 0.0877, macro_f1 : 0.0368\n",
						"\n",
						"epoch #001 train phase - \n",
						"\tloss : 2.3014, accuracy : 0.0883, macro_f1 : 0.0358\n",
						"\n",
						"epoch #002 train phase - \n",
						"\tloss : 2.2976, accuracy : 0.0883, macro_f1 : 0.0274\n",
						"\n",
						"epoch #003 train phase - \n",
						"\tloss : 2.2939, accuracy : 0.0917, macro_f1 : 0.0298\n",
						"\n",
						"epoch #004 train phase - \n",
						"\tloss : 2.2900, accuracy : 0.1009, macro_f1 : 0.0398\n",
						"\n",
						"epoch #005 train phase - \n",
						"\tloss : 2.2862, accuracy : 0.1135, macro_f1 : 0.0513\n",
						"\n",
						"epoch #006 train phase - \n",
						"\tloss : 2.2822, accuracy : 0.1382, macro_f1 : 0.0558\n",
						"\n",
						"epoch #007 train phase - \n",
						"\tloss : 2.2782, accuracy : 0.1560, macro_f1 : 0.0563\n",
						"\n",
						"epoch #008 train phase - \n",
						"\tloss : 2.2742, accuracy : 0.1743, macro_f1 : 0.0596\n",
						"\n",
						"epoch #009 train phase - \n",
						"\tloss : 2.2701, accuracy : 0.1829, macro_f1 : 0.0618\n",
						"\n",
						"epoch #010 train phase - \n",
						"\tloss : 2.2659, accuracy : 0.1864, macro_f1 : 0.0645\n",
						"\n",
						"epoch #011 train phase - \n",
						"\tloss : 2.2617, accuracy : 0.1892, macro_f1 : 0.0799\n",
						"\n",
						"epoch #012 train phase - \n",
						"\tloss : 2.2575, accuracy : 0.1829, macro_f1 : 0.0948\n",
						"\n",
						"epoch #013 train phase - \n",
						"\tloss : 2.2533, accuracy : 0.1789, macro_f1 : 0.0999\n",
						"\n",
						"epoch #014 train phase - \n",
						"\tloss : 2.2490, accuracy : 0.1697, macro_f1 : 0.1043\n",
						"\n",
						"epoch #015 train phase - \n",
						"\tloss : 2.2447, accuracy : 0.1594, macro_f1 : 0.1064\n",
						"\n",
						"epoch #016 train phase - \n",
						"\tloss : 2.2404, accuracy : 0.2001, macro_f1 : 0.1268\n",
						"\n",
						"epoch #017 train phase - \n",
						"\tloss : 2.2361, accuracy : 0.3068, macro_f1 : 0.1672\n",
						"\n",
						"epoch #018 train phase - \n",
						"\tloss : 2.2318, accuracy : 0.3865, macro_f1 : 0.1889\n",
						"\n",
						"epoch #019 train phase - \n",
						"\tloss : 2.2275, accuracy : 0.3928, macro_f1 : 0.2639\n",
						"\n",
						"epoch #020 train phase - \n",
						"\tloss : 2.2233, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #021 train phase - \n",
						"\tloss : 2.2190, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #022 train phase - \n",
						"\tloss : 2.2148, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #023 train phase - \n",
						"\tloss : 2.2106, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #024 train phase - \n",
						"\tloss : 2.2064, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #025 train phase - \n",
						"\tloss : 2.2023, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #026 train phase - \n",
						"\tloss : 2.1983, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #027 train phase - \n",
						"\tloss : 2.1942, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #028 train phase - \n",
						"\tloss : 2.1903, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #029 train phase - \n",
						"\tloss : 2.1864, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #030 train phase - \n",
						"\tloss : 2.1826, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #031 train phase - \n",
						"\tloss : 2.1789, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #032 train phase - \n",
						"\tloss : 2.1752, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #033 train phase - \n",
						"\tloss : 2.1717, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #034 train phase - \n",
						"\tloss : 2.1682, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #035 train phase - \n",
						"\tloss : 2.1648, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #036 train phase - \n",
						"\tloss : 2.1616, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #037 train phase - \n",
						"\tloss : 2.1584, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #038 train phase - \n",
						"\tloss : 2.1553, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #039 train phase - \n",
						"\tloss : 2.1524, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #040 train phase - \n",
						"\tloss : 2.1495, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #041 train phase - \n",
						"\tloss : 2.1467, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #042 train phase - \n",
						"\tloss : 2.1441, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #043 train phase - \n",
						"\tloss : 2.1415, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #044 train phase - \n",
						"\tloss : 2.1391, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #045 train phase - \n",
						"\tloss : 2.1367, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #046 train phase - \n",
						"\tloss : 2.1344, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #047 train phase - \n",
						"\tloss : 2.1323, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #048 train phase - \n",
						"\tloss : 2.1302, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"epoch #049 train phase - \n",
						"\tloss : 2.1282, accuracy : 0.3933, macro_f1 : 0.3412\n",
						"\n",
						"finished training\n"
					]
				}
			],
			"source": [
				"train.train_dataset1(\n",
				"    model, d1_train_loader,\n",
				"    loss_ce, optimizer, scheduler,\n",
				"    epochs=epochs,\n",
				"    save_model_dir=\".model\", device=device\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"id": "bbc30e3b-334e-4e1a-8063-e893b6619ba4",
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"<All keys matched successfully>"
						]
					},
					"execution_count": 16,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"model = CRNN(n_fft=cfg1[\"n_fft\"], class_num=cfg1[\"class_num\"]).to(device)\n",
				"model.load_state_dict(torch.load(\".model/best_model_transferred.pt\"))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"id": "1ade3167-93a0-49e2-bce6-3b0861a674bc",
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>predicted value</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>3</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>3</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>3</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>3</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>3</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"   predicted value\n",
							"0                3\n",
							"1                3\n",
							"2                3\n",
							"3                3\n",
							"4                3"
						]
					},
					"execution_count": 17,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"pd_preds = eval.eval_dataset1(model, d1_test_loader, save_model_dir=\".model\", device=device, save_submission=True)\n",
				"pd_preds.head()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"id": "dcdf91d3-5090-474f-9ad4-8986330111e1",
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>real value</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"   real value\n",
							"0           8\n",
							"1           8\n",
							"2           8\n",
							"3           8\n",
							"4           8"
						]
					},
					"execution_count": 18,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"import pandas as pd\n",
				"\n",
				"answer = []\n",
				"for idx, x_y in enumerate(d1_test_loader):\n",
				"    y = x_y[-1]\n",
				"    answer.extend(y.cpu().numpy())\n",
				"torch.cuda.empty_cache()\n",
				"\n",
				"y_true = pd.DataFrame(answer, columns=['real value'])\n",
				"y_true.head()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"id": "9e157d08-5803-44d3-9740-61cc69934ccf",
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/html": [
							"<div>\n",
							"<style scoped>\n",
							"    .dataframe tbody tr th:only-of-type {\n",
							"        vertical-align: middle;\n",
							"    }\n",
							"\n",
							"    .dataframe tbody tr th {\n",
							"        vertical-align: top;\n",
							"    }\n",
							"\n",
							"    .dataframe thead th {\n",
							"        text-align: right;\n",
							"    }\n",
							"</style>\n",
							"<table border=\"1\" class=\"dataframe\">\n",
							"  <thead>\n",
							"    <tr style=\"text-align: right;\">\n",
							"      <th></th>\n",
							"      <th>predicted value</th>\n",
							"      <th>real value</th>\n",
							"    </tr>\n",
							"  </thead>\n",
							"  <tbody>\n",
							"    <tr>\n",
							"      <th>0</th>\n",
							"      <td>3</td>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>1</th>\n",
							"      <td>3</td>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>2</th>\n",
							"      <td>3</td>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>3</th>\n",
							"      <td>3</td>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"    <tr>\n",
							"      <th>4</th>\n",
							"      <td>3</td>\n",
							"      <td>8</td>\n",
							"    </tr>\n",
							"  </tbody>\n",
							"</table>\n",
							"</div>"
						],
						"text/plain": [
							"   predicted value  real value\n",
							"0                3           8\n",
							"1                3           8\n",
							"2                3           8\n",
							"3                3           8\n",
							"4                3           8"
						]
					},
					"execution_count": 19,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"y_pred_true = pd.DataFrame.from_dict({\n",
				"        \"predicted value\": pd_preds[\"predicted value\"],\n",
				"        \"real value\": y_true[\"real value\"]\n",
				"    })\n",
				"\n",
				"y_pred_true.head()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 20,
			"id": "a427c6ac-99ac-48ba-afaf-175f73defa8c",
			"metadata": {},
			"outputs": [
				{
					"data": {
						"text/plain": [
							"0.01818181818181818"
						]
					},
					"execution_count": 20,
					"metadata": {},
					"output_type": "execute_result"
				}
			],
			"source": [
				"from sklearn.metrics import f1_score\n",
				"f1_score(y_pred_true[\"predicted value\"], y_pred_true[\"real value\"], average='macro')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 21,
			"id": "1d8159fc-3cc9-4a8f-b299-a7a461772df4",
			"metadata": {},
			"outputs": [
				{
					"data": {
						"image/png": "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\n",
						"text/plain": [
							"<Figure size 432x288 with 2 Axes>"
						]
					},
					"metadata": {
						"needs_background": "light"
					},
					"output_type": "display_data"
				}
			],
			"source": [
				"import matplotlib.pyplot as plt\n",
				"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
				"\n",
				"cm = confusion_matrix(y_pred_true[\"real value\"], y_pred_true[\"predicted value\"])\n",
				"disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
				"disp.plot()\n",
				"plt.show()"
			]
		}
	]
}